# ğŸ“‹ æ–‡æ¡£æŠ½å–å®éªŒè¯¦ç»†æ­¥éª¤

## 1. ç¯å¢ƒå‡†å¤‡

### 1.1 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
conda create -n latentmas python=3.10 -y
conda activate latentmas
```

### 1.2 å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 1.3 è®¾ç½®HuggingFaceç¼“å­˜ç›®å½•ï¼ˆå¯é€‰ï¼‰
```bash
# Windows PowerShell
$env:HF_HOME = "E:\huggingface_cache"
$env:TRANSFORMERS_CACHE = $env:HF_HOME

# Linux/Mac
export HF_HOME=/path/to/huggingface
export TRANSFORMERS_CACHE=$HF_HOME
```

---

## 2. æ•°æ®å‡†å¤‡

### 2.1 DocREDï¼ˆæ–‡æ¡£çº§å…³ç³»æŠ½å–ï¼‰
```
æ•°æ®ä½ç½®: e:/Edge Download/dev.json  (æœ‰æ ‡ç­¾ï¼Œå¯è¯„ä¼°)
          e:/Edge Download/test (1).json  (æ— æ ‡ç­¾ï¼Œéœ€æäº¤CodaLab)
æ ¼å¼: {"title": "", "sents": [[]], "vertexSet": [...], "labels": [...]}
```

### 2.2 CORDï¼ˆæ”¶æ®ä¿¡æ¯æŠ½å–ï¼‰
```
æ•°æ®ä½ç½®: e:/Edge Download/samples.json
æ ¼å¼: {"samples": [{"filepath": "data/xxx.png", "num_items": 22, "total_price": "..."}]}
éœ€è¦: samples.jsonåŒç›®å½•ä¸‹æœ‰data/æ–‡ä»¶å¤¹åŒ…å«å›¾ç‰‡
```

### 2.3 FUNSDï¼ˆè¡¨å•ç†è§£ï¼‰
```
æ•°æ®ä½ç½®: instances_test.json
æ ¼å¼: COCO-style {"images": [...], "annotations": [...]}
éœ€è¦: annotations/æ–‡ä»¶å¤¹ï¼ˆåŒ…å«segm_fileï¼‰å’Œimages/æ–‡ä»¶å¤¹
```

### 2.4 FinER-139ï¼ˆé‡‘èå®ä½“è¯†åˆ«ï¼‰
```
æ ¼å¼: {"tokens": [...], "ner_tags": [...]}
éœ€è¦: åŒç›®å½•ä¸‹æœ‰tag2id.jsonæ˜ å°„æ–‡ä»¶
```

---

## 3. è¿è¡Œå®éªŒ

### 3.1 DocRED å…³ç³»æŠ½å–

#### Sequentialæ¨¡å¼ï¼ˆlatent_masï¼‰
```bash
python run.py \
    --method latent_mas \
    --model_name Qwen/Qwen2.5-1.5B-Instruct \
    --task docred \
    --doc_path "e:/Edge Download/dev.json" \
    --prompt sequential \
    --extraction_mode chunks \
    --chunk_size 3000 \
    --max_samples 100 \
    --output_path docred_latent_sequential.json
```

#### Hierarchicalæ¨¡å¼
```bash
python run.py \
    --method latent_mas \
    --model_name Qwen/Qwen2.5-1.5B-Instruct \
    --task docred \
    --doc_path "e:/Edge Download/dev.json" \
    --prompt hierarchical \
    --extraction_mode partitioned \
    --num_partitions 3 \
    --max_samples 100 \
    --output_path docred_latent_hierarchical.json
```

#### TextMASå¯¹æ¯”å®éªŒ
```bash
python run.py \
    --method text_mas \
    --model_name Qwen/Qwen2.5-1.5B-Instruct \
    --task docred \
    --doc_path "e:/Edge Download/dev.json" \
    --prompt sequential \
    --max_samples 100 \
    --output_path docred_textmas.json
```

#### Baselineå¯¹æ¯”
```bash
python run.py \
    --method baseline \
    --model_name Qwen/Qwen2.5-1.5B-Instruct \
    --task docred \
    --doc_path "e:/Edge Download/dev.json" \
    --max_samples 100 \
    --output_path docred_baseline.json
```

---

### 3.2 CORD æ”¶æ®æŠ½å–ï¼ˆå¤šæ¨¡æ€ï¼‰

#### ä½¿ç”¨è§†è§‰æ¨¡å‹
```bash
python run.py \
    --method latent_mas \
    --model_name Qwen/Qwen2-VL-2B-Instruct \
    --task cord \
    --doc_path "e:/Edge Download/samples.json" \
    --use_vision_model \
    --prompt sequential \
    --max_samples 50 \
    --output_path cord_results.json
```

#### ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
```bash
python run.py \
    --method latent_mas \
    --model_name Qwen/Qwen2-VL-7B-Instruct \
    --task cord \
    --doc_path "e:/Edge Download/samples.json" \
    --use_vision_model \
    --max_samples 50 \
    --output_path cord_7b_results.json
```

---

### 3.3 FUNSD è¡¨å•ç†è§£ï¼ˆå¤šæ¨¡æ€ï¼‰

```bash
python run.py \
    --method latent_mas \
    --model_name Qwen/Qwen2-VL-7B-Instruct \
    --task funsd \
    --doc_path "path/to/instances_test.json" \
    --use_vision_model \
    --prompt sequential \
    --max_samples 50 \
    --output_path funsd_results.json
```

---

### 3.4 FinER-139 é‡‘èå®ä½“è¯†åˆ«

```bash
python run.py \
    --method latent_mas \
    --model_name Qwen/Qwen2.5-4B-Instruct \
    --task finer \
    --doc_path "path/to/finer_data.json" \
    --prompt sequential \
    --max_samples 100 \
    --output_path finer_results.json
```

---

## 4. å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|-----|------|-------|
| `--method` | æ–¹æ³•é€‰æ‹©: baseline / text_mas / latent_mas | å¿…å¡« |
| `--model_name` | æ¨¡å‹åç§° | å¿…å¡« |
| `--task` | ä»»åŠ¡: docred / cord / funsd / finer | gsm8k |
| `--doc_path` | æ•°æ®æ–‡ä»¶è·¯å¾„ | None |
| `--prompt` | MASæ¶æ„: sequential / hierarchical | sequential |
| `--extraction_mode` | å¤„ç†æ¨¡å¼: chunks / partitioned | chunks |
| `--chunk_size` | æ¯å—å­—ç¬¦æ•° | 3000 |
| `--chunk_overlap` | å—ä¹‹é—´é‡å  | 300 |
| `--num_partitions` | åˆ†åŒºæ•°é‡(hierarchical) | 3 |
| `--max_samples` | æœ€å¤§æ ·æœ¬æ•°ï¼Œ-1ä¸ºå…¨éƒ¨ | -1 |
| `--max_new_tokens` | æœ€å¤§ç”Ÿæˆtokenæ•° | 4096 |
| `--latent_steps` | LatentMASæ½œç©ºé—´æ­¥æ•° | 0 |
| `--use_vision_model` | ä½¿ç”¨è§†è§‰æ¨¡å‹ | False |
| `--output_path` | ç»“æœä¿å­˜è·¯å¾„ | è‡ªåŠ¨ç”Ÿæˆ |

---

## 5. æŸ¥çœ‹ç»“æœ

### 5.1 ç»ˆç«¯è¾“å‡º
è¿è¡Œè¿‡ç¨‹ä¸­ä¼šå®æ—¶æ˜¾ç¤ºï¼š
- æ¯ä¸ªæ ·æœ¬çš„Agentå¤„ç†è¿‡ç¨‹
- é¢„æµ‹ç»“æœ vs æ ‡å‡†ç­”æ¡ˆ
- æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡

### 5.2 ç»“æœæ–‡ä»¶æ ¼å¼
```json
{
  "summary": {
    "method": "latent_mas",
    "model": "Qwen/Qwen2.5-1.5B-Instruct",
    "task": "docred",
    "precision": 0.6234,
    "recall": 0.5821,
    "f1": 0.6021,
    "total_time_sec": 3456.78
  },
  "predictions": [
    {
      "question": "æ–‡æ¡£å†…å®¹...",
      "prediction": "{\"relations\": [...]}",
      "gold": "{\"relations\": [...]}",
      "correct": true,
      "agents": [...]
    }
  ]
}
```

---

## 6. è¯„ä¼°æŒ‡æ ‡

### DocRED
- Precision, Recall, F1ï¼ˆå…³ç³»ä¸‰å…ƒç»„çº§åˆ«ï¼‰

### CORD
- é€å­—æ®µå‡†ç¡®ç‡ï¼šnum_items, subtotal_price, total_priceç­‰
- Overall Accuracy

### FUNSD
- Entity F1ï¼ˆå®ä½“è¯†åˆ«ï¼‰
- Relation F1ï¼ˆå…³ç³»æŠ½å–ï¼‰
- Overall F1

### FinER-139
- Precision, Recall, F1ï¼ˆå®ä½“çº§åˆ«ï¼‰

---

## 7. æ¨èå®éªŒæ–¹æ¡ˆ

### 7.1 å¿«é€ŸéªŒè¯ï¼ˆå°è§„æ¨¡ï¼‰
```bash
# å…ˆç”¨å°‘é‡æ ·æœ¬æµ‹è¯•æµç¨‹æ˜¯å¦æ­£ç¡®
python run.py --method latent_mas --model_name Qwen/Qwen2.5-1.5B-Instruct \
              --task docred --doc_path "dev.json" --max_samples 10
```

### 7.2 å®Œæ•´å¯¹æ¯”å®éªŒ
```bash
# å¯¹æ¯ä¸ªæ•°æ®é›†ï¼Œè¿è¡Œä¸‰ç§æ–¹æ³•ï¼š
# 1. baseline (å•Agent)
# 2. text_mas (æ–‡æœ¬ä¼ é€’å¤šAgent)
# 3. latent_mas (æ½œç©ºé—´å¤šAgent)

# å¹¶å¯¹æ¯”ä¸¤ç§æ¶æ„ï¼š
# - sequential (é¡ºåº)
# - hierarchical (å±‚çº§)
```

### 7.3 æ¨¡å‹è§„æ¨¡å¯¹æ¯”
```bash
# å¯¹æ¯”ä¸åŒæ¨¡å‹å¤§å°çš„æ•ˆæœï¼š
# - Qwen2.5-1.5B-Instruct
# - Qwen2.5-4B-Instruct
# - Qwen2.5-7B-Instruct
# - Qwen2.5-14B-Instruct
```

---

## 8. å¸¸è§é—®é¢˜

### Q: æ˜¾å­˜ä¸è¶³
```bash
# ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
--model_name Qwen/Qwen2.5-1.5B-Instruct

# å‡å°‘batch size
--generate_bs 1

# å‡å°‘æœ€å¤§ç”Ÿæˆé•¿åº¦
--max_new_tokens 2048
```

### Q: é€Ÿåº¦å¤ªæ…¢
```bash
# ä½¿ç”¨vLLMåŠ é€Ÿï¼ˆéœ€è¦é¢å¤–å®‰è£…ï¼‰
pip install vllm
python run.py ... --use_vllm
```

### Q: CUDAé”™è¯¯
```bash
# æŒ‡å®šGPUè®¾å¤‡
--device cuda:0
# æˆ–ä½¿ç”¨CPU
--device cpu
```

---

## 9. è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆæäº¤å®˜æ–¹è¯„æµ‹ï¼‰

### DocRED CodaLabæäº¤æ ¼å¼
```json
[
  {"title": "æ–‡æ¡£æ ‡é¢˜", "h_idx": 0, "t_idx": 1, "r": "P17"},
  ...
]
```

å¦‚éœ€è½¬æ¢ï¼Œå¯æ‰‹åŠ¨å¤„ç†results.jsonä¸­çš„predictionsã€‚
