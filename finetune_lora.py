"""
LoRAå¾®è°ƒè„šæœ¬ - é’ˆå¯¹æ–‡æ¡£ä¿¡æ¯æŠ½å–ä»»åŠ¡å¾®è°ƒQwenæ¨¡å‹

âš ï¸ å…³é”®çŸ›ç›¾ï¼šç†æƒ³ä¸ç°å®çš„å†²çª

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç†æƒ³ï¼ˆLatentMASå“²å­¦ï¼‰: Training-Freeï¼Œagentåä½œé€šè¿‡promptå®ç°
ç°å®ï¼ˆå®éªŒå‘ç°ï¼‰      : å°æ¨¡å‹directè®­ç»ƒåæ— æ³•ç†è§£å¤æ‚agent prompts
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” é—®é¢˜æœ¬è´¨ï¼šBase Modelçš„In-Context Learningèƒ½åŠ›

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¼ºBase Model (14B+, å¦‚Qwen2.5-72B):                 â”‚
â”‚ âœ… å¤©ç„¶ç†è§£"You are a Planner Agent..."            â”‚
â”‚ âœ… Directè®­ç»ƒ + LatentMASæ¨ç† = æ€§èƒ½æ­£å¸¸            â”‚
â”‚ âœ… ç¬¦åˆLatentMASçš„Training-Freeå“²å­¦                 â”‚
â”‚                                                     â”‚
â”‚ å¼±Base Model (4B-7B):                               â”‚
â”‚ âŒ éš¾ä»¥ç†è§£å¤æ‚çš„agent role prompts                â”‚
â”‚ âŒ Directè®­ç»ƒ + LatentMASæ¨ç† = æ€§èƒ½å´©æºƒ (F1: 68%â†’25%) â”‚
â”‚ âŒ éœ€è¦å¦¥åï¼šè¦ä¹ˆæ¢æ¨¡å‹ï¼Œè¦ä¹ˆagent-awareè®­ç»ƒ        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š å®éªŒæ•°æ®ï¼ˆDocREDä»»åŠ¡ï¼ŒQwen3-VL-4Bï¼‰

Training Mode    Inference Method    F1 Score    ç¬¦åˆå“²å­¦?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
direct           direct              ~55%        âœ… æ˜¯
direct           latent_mas          ~25%        âœ… æ˜¯ï¼ˆä½†æ€§èƒ½å·®ï¼‰
latent_mas       latent_mas          ~68%        âŒ å¦ï¼ˆæ€§èƒ½æœ€å¥½ï¼‰

ğŸ¯ é€‰æ‹©æŒ‡å—

æ–¹æ¡ˆ1: æ¢æ›´å¼ºçš„Base Modelï¼ˆæœ€æ¨èï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python finetune_lora.py \
    --model_name Qwen/Qwen2.5-14B-Instruct \  # æ¢æˆ14B+
    --training_mode direct \
    --task docred

ä¼˜åŠ¿: 
âœ… ç¬¦åˆLatentMASå“²å­¦
âœ… Training-Freeåä½œ
âœ… çµæ´»æ€§æœ€å¼º

å‰æ: éœ€è¦è¶³å¤Ÿçš„GPUèµ„æº

æ–¹æ¡ˆ2: å¦¥åä½¿ç”¨Agent-Awareè®­ç»ƒï¼ˆç°å®é€‰æ‹©ï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python finetune_lora.py \
    --model_name Qwen/Qwen3-VL-4B-Instruct \  # å°æ¨¡å‹
    --training_mode latent_mas \              # å¦¥å
    --prompt_style sequential \
    --task docred

ä¼˜åŠ¿:
âœ… æ€§èƒ½æœ€å¥½ï¼ˆF1 ~68%ï¼‰
âœ… é€‚ç”¨äºèµ„æºå—é™åœºæ™¯

åŠ£åŠ¿:
âŒ è¿èƒŒLatentMASçš„çµæ´»æ€§
âŒ å›ºåŒ–äº†agentåä½œæ¨¡å¼
âŒ å¿…é¡»åœ¨æ¨ç†æ—¶ä½¿ç”¨ç›¸åŒprompté£æ ¼

æ–¹æ¡ˆ3: Directè®­ç»ƒ + Directæ¨ç†ï¼ˆBaselineï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python finetune_lora.py --training_mode direct --task docred
python run.py --method direct --lora_weights ./lora_weights/docred

ä¼˜åŠ¿:
âœ… ç¬¦åˆå“²å­¦
âœ… è®­ç»ƒ-æ¨ç†ä¸€è‡´

åŠ£åŠ¿:
âŒ æ²¡æœ‰multi-agentåä½œçš„æ€§èƒ½æå‡ï¼ˆF1 ~55%ï¼‰

ğŸ’¡ ç»“è®º

å¦‚æœä½ å…³å¿ƒ:
- æ€§èƒ½æœ€ä¼˜ â†’ ç”¨ latent_mas è®­ç»ƒï¼ˆæ‰¿è®¤è¿èƒŒå“²å­¦ï¼‰
- å“²å­¦æ­£ç¡® â†’ ç”¨ direct è®­ç»ƒ + æ›´å¼ºçš„Base Model
- èµ„æºå—é™ â†’ åœ¨æ€§èƒ½å’Œå“²å­¦ä¹‹é—´åštrade-off

é»˜è®¤è®¾ç½®: latent_masï¼ˆä¼˜å…ˆæ€§èƒ½ï¼Œå› ä¸ºå¤§å¤šæ•°äººç”¨çš„æ˜¯å°æ¨¡å‹ï¼‰
"""

import os
import json
import torch
import argparse
from typing import List, Dict, Tuple
from transformers import AutoModelForVision2Seq, AutoProcessor, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, TaskType
from torch.utils.data import Dataset
from PIL import Image
from data import load_funsd, load_docred, load_cord, load_finer


# ============= Agent Prompts for LatentMAS Training =============

def get_agent_prompts(task: str, question: str, entity_list: str = "", mode: str = "sequential") -> Dict[str, str]:
    """
    è·å–4ä¸ªAgentçš„promptæ¨¡æ¿
    
    Args:
        task: ä»»åŠ¡ç±»å‹ (docred/funsd/cord/finer)
        question: æ–‡æ¡£å†…å®¹
        entity_list: å®ä½“åˆ—è¡¨ï¼ˆDocREDä¸“ç”¨ï¼‰
        mode: sequential(é¡ºåºåä½œ) æˆ– hierarchical(å¹¶è¡Œåˆ†å·¥)
    """
    
    if mode == "hierarchical":
        return get_agent_prompts_hierarchical(task, question, entity_list)
    else:
        return get_agent_prompts_sequential(task, question, entity_list)


def get_agent_prompts_sequential(task: str, question: str, entity_list: str = "") -> Dict[str, str]:
    """Sequentialæ¨¡å¼: Plannerâ†’Criticâ†’Refinerâ†’Judger é¡ºåºåä½œ"""
    
    if task == "docred":
        planner = f"""You are a Document Scanner Agent (Phase 1: Information Discovery).

Task: Document-level relation extraction.

Document:
{question}

Entities in document:
{entity_list}

Instructions:
- Carefully scan and identify all entity mentions
- Note potential relationships between entities
- Consider sentence indices as evidence
- Store findings in latent format

Begin scanning and record findings:"""

        critic = f"""You are a Document Validator Agent (Phase 2: Cross-Verification).

Task: Verify relation extraction accuracy.

The document content and entities are in latent memory (KV Cache).

Instructions:
- Cross-check entity relationships against document (from latent memory)
- Verify evidence sentence indices
- Identify missing or incorrect relations
- Note corrections in latent format

Continue verification:"""

        refiner = f"""You are a Document Structuring Agent (Phase 3: Organization).

Task: Organize extracted relations.

All information is in latent memory (KV Cache).

Instructions:
- Consolidate verified relations
- Resolve any conflicts
- Prepare final extraction structure
- Use Wikidata P-IDs for relations

Continue organization:"""

        judger = f"""Task: Output final relation extraction JSON.

Entities: {entity_list}

Common relations: P17(country), P131(located in), P27(citizenship), P569(birth date), P570(death date), P19(birthplace), P20(death place), P69(educated at), P108(employer), P40(child), P26(spouse).

Output JSON format:
{{"relations": [{{"head": "Entity", "relation": "P17", "tail": "Country", "evidence": [0]}}]}}

Based on previous analysis, output ONLY the final JSON:"""

    elif task == "funsd":
        planner = f"""You are a Form Scanner Agent (Phase 1: Field Detection).

Task: Form understanding and field extraction.

Form content:
{question}

Instructions:
- Identify all form fields and their types
- Classify as: question/answer/header/other
- Note spatial relationships
- Store findings in latent format

Begin scanning:"""

        critic = f"""You are a Form Validator Agent (Phase 2: Link Verification).

Task: Verify form field relationships.

The form content is in latent memory (KV Cache).

Instructions:
- Cross-check question-answer pairings (from latent memory)
- Verify field classifications
- Identify orphaned fields
- Note corrections in latent format

Continue verification:"""

        refiner = f"""You are a Form Structuring Agent (Phase 3: Relationship Mapping).

Task: Finalize form structure.

Instructions:
- Consolidate question-answer pairs
- Confirm all field labels
- Prepare final linking structure

Continue organization:"""

        judger = f"""Task: Output final form extraction JSON.

Format:
{{"entities": [{{"text": "...", "label": "question|answer|header|other"}}], "relations": [{{"head": "question text", "tail": "answer text"}}]}}

Based on previous analysis, output ONLY the final JSON:"""

    elif task == "cord":
        planner = f"""You are a Receipt Scanner Agent (Phase 1: Item Detection).

Task: Receipt/invoice information extraction.

Receipt content:
{question}

Instructions:
- Identify all menu items with prices
- Note subtotal, tax, service charges
- Locate total amount
- Store findings in latent format

Begin scanning:"""

        critic = f"""You are a Receipt Validator Agent (Phase 2: Amount Verification).

Task: Verify extracted amounts.

The receipt content is in latent memory (KV Cache).

Instructions:
- Cross-check item prices and totals (from latent memory)
- Verify mathematical consistency
- Identify missing amounts
- Note corrections in latent format

Continue verification:"""

        refiner = f"""You are a Receipt Structuring Agent (Phase 3: Total Calculation).

Task: Finalize receipt structure.

Instructions:
- Consolidate all items and amounts
- Confirm total calculations
- Prepare final structure

Continue organization:"""

        judger = f"""Task: Output final receipt extraction JSON.

Format:
{{"num_items": N, "subtotal_price": "X.XX", "service_price": "", "tax_price": "", "total_price": "X.XX", "etc": ""}}

Based on previous analysis, output ONLY the final JSON:"""

    elif task == "finer":
        planner = f"""You are a Financial Entity Scanner (Phase 1: Entity Detection).

Task: Financial named entity recognition.

Text:
{question}

Entity types: PER, ORG, LOC, MONEY, DATE, PERCENT, STOCK, METRIC, PRODUCT, LAW

Instructions:
- Identify all financial entities
- Note entity boundaries (start/end positions)
- Classify entity types
- Store findings in latent format

Begin scanning:"""

        critic = f"""You are a Financial Entity Validator (Phase 2: Type Verification).

Task: Verify entity classifications.

Instructions:
- Cross-check entity type assignments
- Verify character positions
- Identify overlapping or missing entities
- Note corrections in latent format

Continue verification:"""

        refiner = f"""You are a Financial Entity Structuring Agent (Phase 3: Position Mapping).

Task: Finalize entity boundaries.

Instructions:
- Consolidate entity spans
- Confirm type classifications
- Calculate exact positions

Continue organization:"""

        judger = f"""Task: Output final entity extraction JSON.

Format:
{{"entities": [{{"text": "Apple", "type": "ORG", "start": 0, "end": 5}}]}}

Based on previous analysis, output ONLY the final JSON:"""

    else:
        planner = f"Scan document:\n{question}"
        critic = "Verify findings."
        refiner = "Organize results."
        judger = "Output final JSON:"
    
    return {
        "planner": planner,
        "critic": critic,
        "refiner": refiner,
        "judger": judger
    }


def get_agent_prompts_hierarchical(task: str, question: str, entity_list: str = "") -> Dict[str, str]:
    """Hierarchicalæ¨¡å¼: å¤šä¸ªpartitionå¹¶è¡Œè¯»å–ï¼Œæœ€åæ±‡æ€»"""
    
    if task == "docred":
        planner = f"""You are Document Partition Reader 1 (Focus: Entity Detection).

Task: Document-level relation extraction.

Document:
{question}

Instructions:
- Extract entities and their mentions from first part
- Note potential relationships
- Store findings in latent format

Partition 1 extraction:"""

        critic = f"""You are Document Partition Reader 2 (Focus: Relation Verification).

Task: Verify and extract relations from middle part.

Document:
{question}

Instructions:
- Cross-check relationships in middle section
- Verify evidence sentences
- Store findings in latent format

Partition 2 extraction:"""

        refiner = f"""You are Document Partition Reader 3 (Focus: Evidence Collection).

Task: Extract evidence from final part.

Document:
{question}

Instructions:
- Identify supporting sentences
- Confirm entity-relation mappings
- Store findings in latent format

Partition 3 extraction:"""

        judger = f"""You are Integration Agent. Consolidate all partition findings.

Entities: {entity_list}

Common relations: P17(country), P131(located in), P27(citizenship), P569(birth date), P570(death date), P19(birthplace), P20(death place), P69(educated at), P108(employer), P40(child), P26(spouse).

Output JSON format:
{{"relations": [{{"head": "Entity", "relation": "P17", "tail": "Country", "evidence": [0]}}]}}

Based on all partitions, output ONLY the final JSON:"""

    elif task == "funsd":
        planner = f"""You are Form Section Reader 1 (Focus: Header Fields).

Task: Extract form headers and sections.

Form content:
{question}

Instructions:
- Identify header and section fields
- Store findings in latent format

Section 1 extraction:"""

        critic = f"""You are Form Section Reader 2 (Focus: Question Fields).

Task: Extract question labels.

Instructions:
- Identify all question/prompt fields
- Store findings in latent format

Section 2 extraction:"""

        refiner = f"""You are Form Section Reader 3 (Focus: Answer Fields).

Task: Extract answer values and link to questions.

Instructions:
- Identify answer fields
- Match with corresponding questions
- Store findings in latent format

Section 3 extraction:"""

        judger = f"""You are Integration Agent. Consolidate form structure.

Format:
{{"entities": [{{"text": "...", "label": "question|answer|header|other"}}], "relations": [{{"head": "question text", "tail": "answer text"}}]}}

Based on all sections, output ONLY the final JSON:"""

    elif task == "cord":
        planner = f"""You are Receipt Section Reader 1 (Focus: Menu Items).

Task: Extract menu items from receipt.

Receipt content:
{question}

Instructions:
- Identify all menu items and prices
- Store findings in latent format

Items extraction:"""

        critic = f"""You are Receipt Section Reader 2 (Focus: Subtotals).

Task: Extract subtotal and service charges.

Instructions:
- Identify subtotal amounts
- Note service charges
- Store findings in latent format

Subtotals extraction:"""

        refiner = f"""You are Receipt Section Reader 3 (Focus: Tax and Total).

Task: Extract tax and total amount.

Instructions:
- Identify tax amount
- Locate final total
- Store findings in latent format

Tax/Total extraction:"""

        judger = f"""You are Integration Agent. Consolidate receipt data.

Format:
{{"num_items": N, "subtotal_price": "X.XX", "service_price": "", "tax_price": "", "total_price": "X.XX", "etc": ""}}

Based on all sections, output ONLY the final JSON:"""

    elif task == "finer":
        planner = f"""You are Text Section Reader 1 (Focus: Organization Entities).

Task: Extract ORG, LOC entities from first part.

Text:
{question}

Entity types focus: ORG, LOC

Instructions:
- Identify organization and location entities
- Note boundaries
- Store findings in latent format

Section 1 extraction:"""

        critic = f"""You are Text Section Reader 2 (Focus: Financial Entities).

Task: Extract MONEY, PERCENT, DATE entities from middle part.

Entity types focus: MONEY, PERCENT, DATE

Instructions:
- Identify monetary amounts, percentages, dates
- Note boundaries
- Store findings in latent format

Section 2 extraction:"""

        refiner = f"""You are Text Section Reader 3 (Focus: Specialized Entities).

Task: Extract PER, STOCK, METRIC entities from final part.

Entity types focus: PER, STOCK, METRIC, PRODUCT, LAW

Instructions:
- Identify person names, stocks, metrics
- Note boundaries
- Store findings in latent format

Section 3 extraction:"""

        judger = f"""You are Integration Agent. Consolidate all entities.

Format:
{{"entities": [{{"text": "Apple", "type": "ORG", "start": 0, "end": 5}}]}}

Based on all sections, output ONLY the final JSON:"""

    else:
        planner = f"Section 1:\n{question}"
        critic = "Section 2 analysis."
        refiner = "Section 3 analysis."
        judger = "Output final JSON:"
    
    return {
        "planner": planner,
        "critic": critic,
        "refiner": refiner,
        "judger": judger
    }


def generate_agent_reasoning(task: str, gold: str, agent_role: str, mode: str = "sequential") -> str:
    """ç”Ÿæˆæ¯ä¸ªagentçš„æ¨ç†è¿‡ç¨‹ï¼ˆç”¨äºè®­ç»ƒï¼‰"""
    
    if mode == "hierarchical":
        # Hierarchicalæ¨¡å¼: æ¯ä¸ªagentå¤„ç†ä¸åŒpartition
        if agent_role == "planner":
            return f"""Partition 1 analysis complete...

Key findings from this section:
- Extracted primary entities/fields
- Noted key information
- Stored in latent representation

[Partition 1 latent state ready]"""

        elif agent_role == "critic":
            return f"""Partition 2 analysis complete...

Key findings from this section:
- Extracted secondary entities/fields
- Cross-referenced with partition 1
- Stored in latent representation

[Partition 2 latent state ready]"""

        elif agent_role == "refiner":
            return f"""Partition 3 analysis complete...

Key findings from this section:
- Extracted remaining entities/fields
- Verified consistency across partitions
- Stored in latent representation

[Partition 3 latent state ready]"""

        elif agent_role == "judger":
            return gold
    
    else:
        # Sequentialæ¨¡å¼: é¡ºåºåä½œ
        if agent_role == "planner":
            return f"""Scanning document for relevant information...

Key observations:
- Identified main entities and relationships
- Noted evidence locations
- Stored initial findings in latent representation

[Latent state updated with document scan results]"""

        elif agent_role == "critic":
            return f"""Verifying extracted information...

Validation results:
- Cross-checked entity references
- Verified relationship accuracy
- Identified areas needing refinement

[Latent state updated with verification results]"""

        elif agent_role == "refiner":
            return f"""Organizing and refining structure...

Refinement complete:
- Consolidated all verified information
- Resolved conflicts
- Prepared final extraction format

[Latent state finalized for output]"""

        elif agent_role == "judger":
            return gold
    
    return ""


class LatentMASDataset(Dataset):
    """æ”¯æŒ4-Agentæµç¨‹çš„è®­ç»ƒæ•°æ®é›†"""
    
    def __init__(self, data_items: List[Dict], processor, task: str, training_mode: str = "latent_mas", prompt_style: str = "sequential"):
        self.data_items = data_items
        self.processor = processor
        self.task = task
        self.training_mode = training_mode
        self.prompt_style = prompt_style  # sequential æˆ– hierarchical
        self.agents = ["planner", "critic", "refiner", "judger"]
    
    def __len__(self):
        return len(self.data_items)
    
    def __getitem__(self, idx):
        item = self.data_items[idx]
        
        question = item.get("question", "")
        gold = item.get("gold", "{}")
        image = item.get("image")
        entity_list = item.get("entity_list", "")
        
        system_msg = "You are Qwen, an expert document extraction assistant. Follow the multi-agent pipeline: scan â†’ verify â†’ organize â†’ output."
        
        if self.training_mode == "latent_mas":
            # å®Œæ•´4-Agentå¤šè½®å¯¹è¯
            messages = self._build_latent_mas_messages(question, gold, entity_list, system_msg, image)
        else:
            # å•è½®ç›´æ¥æ¨ç† (fallback)
            messages = self._build_direct_messages(question, gold, entity_list, system_msg, image)
        
        return self._process_messages(messages, image)
    
    def _build_latent_mas_messages(self, question: str, gold: str, entity_list: str, 
                                    system_msg: str, image) -> List[Dict]:
        """æ„å»ºå®Œæ•´çš„4-Agentå¯¹è¯åºåˆ—"""
        
        agent_prompts = get_agent_prompts(self.task, question, entity_list, mode=self.prompt_style)
        
        messages = [{"role": "system", "content": system_msg}]
        
        # Plannerè½®æ¬¡ (å¯åŒ…å«å›¾åƒ)
        if image:
            planner_content = [
                {"type": "image", "image": image},
                {"type": "text", "text": agent_prompts["planner"]}
            ]
        else:
            planner_content = agent_prompts["planner"]
        
        messages.append({"role": "user", "content": planner_content})
        messages.append({"role": "assistant", "content": generate_agent_reasoning(self.task, gold, "planner", mode=self.prompt_style)})
        
        # Criticè½®æ¬¡
        messages.append({"role": "user", "content": agent_prompts["critic"]})
        messages.append({"role": "assistant", "content": generate_agent_reasoning(self.task, gold, "critic", mode=self.prompt_style)})
        
        # Refinerè½®æ¬¡
        messages.append({"role": "user", "content": agent_prompts["refiner"]})
        messages.append({"role": "assistant", "content": generate_agent_reasoning(self.task, gold, "refiner", mode=self.prompt_style)})
        
        # Judgerè½®æ¬¡ - è¾“å‡ºæœ€ç»ˆJSON
        messages.append({"role": "user", "content": agent_prompts["judger"]})
        messages.append({"role": "assistant", "content": gold})  # æœ€ç»ˆç­”æ¡ˆ
        
        return messages
    
    def _build_direct_messages(self, question: str, gold: str, entity_list: str,
                                system_msg: str, image) -> List[Dict]:
        """æ„å»ºå•è½®ç›´æ¥æ¨ç†å¯¹è¯"""
        
        # ä½¿ç”¨åŸæ¥çš„å•è½®promptæ ¼å¼
        instruction = self._get_direct_instruction(entity_list)
        
        if image:
            user_content = [
                {"type": "image", "image": image},
                {"type": "text", "text": f"{instruction}\n\nDocument text:\n{question}\n\nExtract and output JSON:"}
            ]
        else:
            user_content = f"{instruction}\n\nDocument text:\n{question}\n\nExtract and output JSON:"
        
        return [
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_content},
            {"role": "assistant", "content": gold}
        ]
    
    def _get_direct_instruction(self, entity_list: str) -> str:
        """è·å–å•è½®æ¨ç†çš„æŒ‡ä»¤"""
        if self.task == "docred":
            return f"""Task: Document-level relation extraction.
Entities: {entity_list}
Output: {{"relations": [{{"head": "...", "relation": "P-ID", "tail": "...", "evidence": [0]}}]}}"""
        elif self.task == "funsd":
            return """Task: Form field extraction.
Output: {"entities": [...], "relations": [...]}"""
        elif self.task == "cord":
            return """Task: Receipt extraction.
Output: {"num_items": N, "subtotal_price": "...", "total_price": "..."}"""
        elif self.task == "finer":
            return """Task: Financial NER.
Output: {"entities": [{"text": "...", "type": "...", "start": 0, "end": 5}]}"""
        return "Extract information."
    
    def _process_messages(self, messages: List[Dict], image) -> Dict:
        """å¤„ç†æ¶ˆæ¯å¹¶è¿”å›æ¨¡å‹è¾“å…¥"""
        
        # åº”ç”¨chat template
        if hasattr(self.processor, 'apply_chat_template'):
            text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)
        else:
            text = self._manual_format_messages(messages)
        
        # åŠ¨æ€ç¡®å®šmax_lengthï¼ˆlatent_maséœ€è¦æ›´é•¿çš„åºåˆ—ï¼‰
        max_len = 4096 if self.training_mode == "latent_mas" else 2048
        
        # Tokenizeï¼ˆç»Ÿä¸€å¤„ç†ï¼Œå‡å°‘é‡å¤ä»£ç ï¼‰
        processor_kwargs = {
            "text": [text],
            "return_tensors": "pt",
            "padding": "max_length",
            "max_length": max_len,
            "truncation": True
        }
        
        if image:
            processor_kwargs["images"] = [image]
        
        try:
            inputs = self.processor(**processor_kwargs)
        except Exception as e:
            print(f"Warning: Processor failed with error: {e}")
            # Fallback: ä¸ä½¿ç”¨å›¾åƒ
            processor_kwargs.pop("images", None)
            inputs = self.processor(**processor_kwargs)
        
        input_ids = inputs["input_ids"].squeeze(0)
        attention_mask = inputs["attention_mask"].squeeze(0)
        
        # æ™ºèƒ½label masking: åªè®¡ç®—assistantå›å¤éƒ¨åˆ†çš„loss
        labels = self._create_labels_with_masking(messages, input_ids)
        
        # Maskæ‰padding tokens
        pad_token_id = getattr(self.processor, 'pad_token_id', None) or \
                       getattr(getattr(self.processor, 'tokenizer', None), 'pad_token_id', 0)
        if pad_token_id is not None:
            labels[labels == pad_token_id] = -100
        
        result = {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels,
        }
        
        # æ·»åŠ è§†è§‰ç›¸å…³çš„å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if "pixel_values" in inputs:
            result["pixel_values"] = inputs["pixel_values"].squeeze(0)
        if "image_grid_thw" in inputs:
            result["image_grid_thw"] = inputs["image_grid_thw"].squeeze(0)
        
        return result
    
    def _create_labels_with_masking(self, messages: List[Dict], input_ids: torch.Tensor) -> torch.Tensor:
        """åˆ›å»ºlabelsï¼Œåªå¯¹assistantå›å¤è®¡ç®—loss
        
        ä¿å®ˆç­–ç•¥ï¼šåªmask system promptï¼Œä¿ç•™æ‰€æœ‰å¯¹è¯å†…å®¹
        """
        labels = input_ids.clone()
        
        # ä¿å®ˆç­–ç•¥ï¼šåªmaskå‰é¢å¾ˆå°ä¸€éƒ¨åˆ†ï¼ˆsystem promptå’Œç¬¬ä¸€ä¸ªuserå¼€å¤´ï¼‰
        # è¿™æ ·å¯ä»¥ä¿ç•™æ‰€æœ‰assistantçš„å›å¤ç”¨äºè®­ç»ƒ
        total_len = len(input_ids)
        
        # åªmaskå‰20%ï¼ˆé€šå¸¸åªåŒ…å«system promptå’Œç¬¬ä¸€ä¸ªuserçš„å¼€å¤´ï¼‰
        # è¿™æ ·å¯ä»¥ç¡®ä¿æ‰€æœ‰assistantå›å¤éƒ½å‚ä¸è®­ç»ƒ
        mask_until = int(total_len * 0.2)
        labels[:mask_until] = -100
        
        return labels
    
    def _manual_format_messages(self, messages: List[Dict]) -> str:
        """æ‰‹åŠ¨æ ¼å¼åŒ–æ¶ˆæ¯ï¼ˆfallbackï¼‰"""
        text_parts = []
        for msg in messages:
            role = msg["role"]
            content = msg["content"]
            if isinstance(content, list):
                content = " ".join([c.get("text", "") for c in content if isinstance(c, dict)])
            text_parts.append(f"<|{role}|>\n{content}")
        return "\n".join(text_parts)


# Backward compatibility: keep old class name
DocumentExtractionDataset = LatentMASDataset


def load_training_data(args):
    """åŠ è½½è®­ç»ƒæ•°æ®å¹¶è¿›è¡ŒéªŒè¯"""
    print(f"Loading training data for {args.task}...")
    
    try:
        if args.task == "funsd":
            data_iter = load_funsd(
                doc_path=args.train_data,
                split="train",
                mode="full",
                annotations_dir=args.annotations_dir,
                images_dir=args.image_dir
            )
        elif args.task == "docred":
            data_iter = load_docred(
                doc_path=args.train_data,
                split="train",
                mode="full"
            )
        elif args.task == "cord":
            data_iter = load_cord(
                doc_path=args.train_data,
                split="train",
                mode="full"
            )
        elif args.task == "finer":
            data_iter = load_finer(
                doc_path=args.train_data,
                split="train",
                mode="full"
            )
        else:
            raise ValueError(f"Unsupported task: {args.task}")
        
        data_items = list(data_iter)
        
        if len(data_items) == 0:
            raise ValueError(f"No training data found! Check your --train_data path: {args.train_data}")
        
        # æ•°æ®éªŒè¯
        invalid_count = 0
        valid_items = []
        for item in data_items:
            if not item.get("question") or not item.get("gold"):
                invalid_count += 1
                continue
            valid_items.append(item)
        
        if invalid_count > 0:
            print(f"[Warning] Filtered out {invalid_count} invalid samples (missing question or gold)")
        
        if len(valid_items) == 0:
            raise ValueError("All data samples are invalid!")
        
        print(f"Loaded {len(valid_items)} valid training samples")
        return valid_items
        
    except FileNotFoundError as e:
        raise FileNotFoundError(f"Training data file not found: {args.train_data}. Error: {e}")
    except Exception as e:
        raise RuntimeError(f"Failed to load training data: {e}")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_name", type=str, default="Qwen/Qwen3-VL-4B-Instruct")
    parser.add_argument("--task", type=str, required=True, choices=["funsd", "docred", "cord", "finer"])
    parser.add_argument("--train_data", type=str, required=True)
    parser.add_argument("--annotations_dir", type=str, default=None)
    parser.add_argument("--image_dir", type=str, default=None)
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--epochs", type=int, default=3)
    parser.add_argument("--batch_size", type=int, default=4)
    parser.add_argument("--gradient_accumulation_steps", type=int, default=4)
    parser.add_argument("--learning_rate", type=float, default=2e-4)
    parser.add_argument("--lora_r", type=int, default=16)
    parser.add_argument("--lora_alpha", type=int, default=32)
    parser.add_argument("--lora_dropout", type=float, default=0.05)
    parser.add_argument("--max_train_samples", type=int, default=None, help="Maximum number of training samples (use all if not specified)")
    parser.add_argument("--use_vision_model", action="store_true", help="Use vision-language model (auto-detect if not specified)")
    parser.add_argument("--training_mode", type=str, default="latent_mas", choices=["direct", "latent_mas"],
                       help="Training mode: 'latent_mas' for best performance (default), 'direct' for philosophical purity")
    parser.add_argument("--prompt_style", type=str, default="sequential", choices=["sequential", "hierarchical"],
                       help="[For latent_mas mode] Prompt style: 'sequential' (recommended) or 'hierarchical'")
    args = parser.parse_args()
    
    print(f"[Config] Training mode: {args.training_mode}")
    
    # è‡ªåŠ¨æ£€æµ‹æ˜¯å¦åº”è¯¥ä½¿ç”¨VLæ¨¡å‹
    if not args.use_vision_model:
        # FUNSDå’ŒCORDé»˜è®¤ä½¿ç”¨VLæ¨¡å‹ï¼ŒDocREDå’ŒFinERä½¿ç”¨æ–‡æœ¬æ¨¡å‹
        if args.task in ["funsd", "cord"]:
            args.use_vision_model = True
            print(f"[Auto] Task {args.task} detected, using vision-language model")
        else:
            args.use_vision_model = False
            print(f"[Auto] Task {args.task} detected, using text-only model")
    
    # åŠ è½½æ¨¡å‹å’Œprocessor
    print(f"Loading model: {args.model_name}")
    
    if args.use_vision_model:
        # åŠ è½½VLæ¨¡å‹
        from transformers import AutoProcessor
        model = AutoModelForVision2Seq.from_pretrained(
            args.model_name,
            torch_dtype=torch.bfloat16,
            device_map="auto"
        )
        processor = AutoProcessor.from_pretrained(args.model_name)
    else:
        # åŠ è½½çº¯æ–‡æœ¬æ¨¡å‹
        from transformers import AutoModelForCausalLM, AutoTokenizer
        model = AutoModelForCausalLM.from_pretrained(
            args.model_name,
            torch_dtype=torch.bfloat16,
            device_map="auto"
        )
        processor = AutoTokenizer.from_pretrained(args.model_name)
        if processor.pad_token is None:
            processor.pad_token = processor.eos_token
            processor.pad_token_id = processor.eos_token_id
    
    # é…ç½®LoRA
    print("Configuring LoRA...")
    
    # è‡ªåŠ¨æŸ¥æ‰¾æ¨¡å‹ä¸­çš„linearå±‚ä½œä¸ºtarget_modules
    # è¿™æ ·å¯ä»¥é€‚é…ä¸åŒæ¨¡å‹æ¶æ„ï¼ˆQwen2, Qwen3, Qwen-VLç­‰ï¼‰
    import re
    target_modules = []
    for name, module in model.named_modules():
        if isinstance(module, torch.nn.Linear):
            # æå–å±‚åç§°çš„æœ€åä¸€éƒ¨åˆ†ï¼ˆå¦‚ q_proj, k_projç­‰ï¼‰
            layer_name = name.split('.')[-1]
            if layer_name not in target_modules and not layer_name.startswith('lm_head'):
                target_modules.append(layer_name)
    
    # å¦‚æœè‡ªåŠ¨æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨å¸¸è§çš„target_modules
    if not target_modules:
        target_modules = ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    
    print(f"LoRA target modules: {target_modules}")
    
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=args.lora_r,
        lora_alpha=args.lora_alpha,
        lora_dropout=args.lora_dropout,
        target_modules=target_modules,
        bias="none"
    )
    
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    # ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒæ¨¡å¼å¹¶å¯ç”¨æ¢¯åº¦
    model.train()
    lora_param_count = 0
    for name, param in model.named_parameters():
        if 'lora' in name.lower():
            param.requires_grad = True
            lora_param_count += param.numel()
    
    print(f"LoRA trainable parameters: {lora_param_count:,} ({lora_param_count / 1e6:.2f}M)")
    
    # æ¸…ç†GPUç¼“å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print(f"GPU memory before training: {torch.cuda.memory_allocated() / 1e9:.2f} GB")
    
    # åŠ è½½æ•°æ®
    train_data = load_training_data(args)
    
    # é™åˆ¶è®­ç»ƒæ ·æœ¬æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.max_train_samples is not None and args.max_train_samples > 0:
        original_size = len(train_data)
        train_data = train_data[:args.max_train_samples]
        print(f"Using {len(train_data)} out of {original_size} training samples")
    else:
        print(f"Using all {len(train_data)} training samples")
    
    train_dataset = LatentMASDataset(train_data, processor, args.task, training_mode=args.training_mode, prompt_style=args.prompt_style)
    
    # æ£€æµ‹GPUæ˜¯å¦æ”¯æŒbf16
    use_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8
    if use_bf16:
        print("Using bf16 training (GPU supports it)")
    else:
        print("Using fp16 training (bf16 not supported, falling back to fp16)")
    
    # è®­ç»ƒé…ç½®
    training_args = TrainingArguments(
        output_dir=args.output_dir,
        num_train_epochs=args.epochs,
        per_device_train_batch_size=args.batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        learning_rate=args.learning_rate,
        lr_scheduler_type="cosine",
        warmup_ratio=0.1,
        logging_steps=10,
        save_strategy="steps" if len(train_data) > 1000 else "epoch",
        save_steps=500 if len(train_data) > 1000 else None,
        save_total_limit=3,
        bf16=use_bf16,
        fp16=not use_bf16,
        gradient_checkpointing=False,  # ç¦ç”¨ä»¥é¿å…ä¸LoRAå†²çª
        dataloader_num_workers=0 if len(train_data) < 100 else 2,  # å°æ•°æ®é›†ä¸éœ€è¦å¤šworker
        remove_unused_columns=False,
        report_to="none",
        load_best_model_at_end=False,  # LoRAä¸æ”¯æŒ
        metric_for_best_model=None,
        greater_is_better=None,
        optim="adamw_torch",  # æ˜ç¡®æŒ‡å®šä¼˜åŒ–å™¨
        max_grad_norm=1.0,  # æ¢¯åº¦è£å‰ª
        logging_first_step=True,
        logging_nan_inf_filter=True,  # è¿‡æ»¤NaN/Infæ—¥å¿—
    )
    
    # ç®€å•ç¨³å®šçš„data collator
    def collate_fn(batch):
        """ç®€å•çš„æ‰¹å¤„ç†ï¼šåªstackç›¸åŒshapeçš„tensor"""
        if not batch:
            return {}
        
        collated = {}
        for key in batch[0].keys():
            values = [item[key] for item in batch if key in item and item[key] is not None]
            
            if not values:
                continue
            
            # åªå¤„ç†tensorï¼Œä¸”å¿…é¡»shapeå®Œå…¨ç›¸åŒ
            if isinstance(values[0], torch.Tensor):
                if all(v.shape == values[0].shape for v in values):
                    collated[key] = torch.stack(values)
                else:
                    # shapeä¸åŒï¼Œè·³è¿‡ï¼ˆè®©Trainerè‡ªåŠ¨å¤„ç†ï¼‰
                    pass
            else:
                collated[key] = values
        
        return collated
    
    # è®­ç»ƒ
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        data_collator=collate_fn
    )
    
    print("\n" + "="*60)
    print("Starting training...")
    print(f"Total samples: {len(train_dataset)}")
    print(f"Effective batch size: {args.batch_size * args.gradient_accumulation_steps}")
    print(f"Total steps: ~{len(train_dataset) // (args.batch_size * args.gradient_accumulation_steps) * args.epochs}")
    print("="*60 + "\n")
    
    try:
        trainer.train()
    except Exception as e:
        print(f"\nâŒ Training failed with error: {e}")
        import traceback
        traceback.print_exc()
        
        # ä¿å­˜å½“å‰æ¨¡å‹çŠ¶æ€ï¼ˆå³ä½¿å¤±è´¥ï¼‰
        try:
            emergency_dir = args.output_dir + "_emergency"
            print(f"\nAttempting to save emergency checkpoint to {emergency_dir}...")
            model.save_pretrained(emergency_dir)
            processor.save_pretrained(emergency_dir)
            print("Emergency checkpoint saved.")
        except:
            print("Failed to save emergency checkpoint.")
        
        raise
    
    # ä¿å­˜
    print(f"\n{'='*60}")
    print(f"Saving LoRA weights to {args.output_dir}")
    try:
        model.save_pretrained(args.output_dir)
        processor.save_pretrained(args.output_dir)
        print("âœ… LoRA weights saved successfully!")
    except Exception as e:
        print(f"âŒ Failed to save LoRA weights: {e}")
        raise
    
    print(f"{'='*60}")
    print("ğŸ‰ Training completed successfully!")
    print(f"\nTo use the trained LoRA:")
    print(f"  python run.py --method latent_mas --lora_weights {args.output_dir} --task {args.task}")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()
